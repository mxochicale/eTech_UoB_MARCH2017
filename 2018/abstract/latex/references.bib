@inproceedings {durr2015,
booktitle = {EG 2015 - Posters},
editor = {B. Solenthaler and E. Puppo},
title = {{Deep Learning on a Raspberry Pi for Real Time Face Recognition}},
author = {Durr, Oliver and Pauchard, Yves and Browarnik, Diego and Axthelm, Rebekka and Loeser, Martin},
year = {2015},
publisher = {The Eurographics Association},
DOI = {10.2312/egp.20151036}
}


@misc{matelabs2017,
  title  = "Why do we need the Democratization of Machine Learning?",
  author = "MateLabs",
  year = {2017},
  Howpublished = {\url{https://medium.com/startup-grind/why-do-we-need-the-democratization-of-machine-learning-80104e43c76f}},
  note = {April 27, 2017 (accessed December 08, 2017)},
}




@Inbook{Ruiz-Garcia2016,
author="Ruiz-Garcia, Ariel
and Elshaw, Mark
and Altahhan, Abdulrahman
and Palade, Vasile",
editor="Villa, Alessandro E.P.
and Masulli, Paolo
and Pons Rivero, Antonio Javier",
title="Deep Learning for Emotion Recognition in Faces",
bookTitle="Artificial Neural Networks and Machine Learning -- ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="38--46",
abstract="Deep Learning (DL) has shown real promise for the classification efficiency for emotion recognition problems. In this paper we present experimental results for a deeply-trained model for emotion recognition through the use of facial expression images. We explore two Convolutional Neural Network (CNN) architectures that offer automatic feature extraction and representation, followed by fully connected softmax layers to classify images into seven emotions. The first architecture explores the impact of reducing the number of deep learning layers and the second splits the input images horizontally into two streams based on eye and mouth positions. The first proposed architecture produces state of the art results with an accuracy rate of 96.93 {\%} and the second architecture with split input produces an average accuracy rate of 86.73 {\%}, respectively.",
isbn="978-3-319-44781-0",
doi="10.1007/978-3-319-44781-0_5",
url="https://doi.org/10.1007/978-3-319-44781-0_5"
}



@misc{ho2016,
author = {Jostine Ho},
title = {Facial Emotion Recognition},
year = {2016},
publisher = {GitHub},
journal = {GitHub repository},
Howpublished = {\url{https://github.com/JostineHo/mememoji}},
note = {Accessed December 08, 2017},
}
commit = {d2c2f7892281849cc632b9f85367f0a2b62ec098},
